(1) A documentation of the internals would be useful.

(2) Add unit testing for lisp-unit. I think the approach should be to
    note some functions and macros as identities that have be verified
    or are logically correct. All tests of lisp-unit should then be
    defined in terms of the identity functions. Maybe a core set of
    functionality should be verified using standard CL comparisons
    such as eq, eql, =, etc.

(3) Fixtures

(4) Test Suites

(5) Generate a tutorial describing how to use LISP-UNIT.

(6) Improve the test report. Initially, it would be useful to only
    specifically report the failures and otherwise just report the
    overall summary. Other improvements might be some sort of progress
    indication, like 'PPPPFPPPFFFP.......' where P is pass, F is fail
    and (.) is not performed yet. Ideas here are welcome.

(7) Design better data structures for the sequence and array error
    results. The data structure is currently a nested list. Should
    probably be a structure or class. Maybe a hash table.

(8) Better integrate the numeric diagnostic functions with the numeric
    assertions. Currently, the VALUE and FORM argument of the
    assertion must be repeated as arguments to the diagnostic
    function. The intent is that you simply note the diagnostic
    function that you wish to apply to the test in the event of a
    failure and the VALUE and FORM arguments are automagically passed
    to that function.

(9) Interactive correction of tests. Something along the lines of the
    debugger, maybe actually using the debugger. I envision a
    work-flow scenario where you run all of the tests and see X of Y
    tests failed. Now you enter a form like

    CL-USER> (lisp-unit:run-failed-tests :interactive t)

    where the default for interactive is nil. Actually, this approach
    could also satisfy the reporting requirements. Anyway, the first
    failed test is executed reporting the results and you are provided
    a prompt with some options. The options could be along the lines
    of abort the testing, pick a diagnostic function to execute or
    re-run the test. If the re-run the test option is chosen, it
    should be after modifications to the definition of the test or the
    routine being tested are made. The idea for this interactive
    correction feature is to tighten the debug loop. Input on this
    idea is highly welcome.

(*) Benchmarking
